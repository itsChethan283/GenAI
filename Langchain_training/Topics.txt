• What is LangChain
• Installation of LangChain
• LangChain Python Packages
• Getting Started Quickly
• LangChain Model I/O
❖ Model Concepts
❖ Prompts
    ▪ Prompt composition
    ▪ Few-shot prompt templates
    ▪ Types of MessagePromptTemplate
    ▪ Partial prompt templates
    ▪ Pipeline
❖ Chat Models
    ▪ Quickstart
    ▪ Function Calling
    ▪ Tracking token usage
❖ LLMs
    ▪ LLM providers
❖ Output Parsers
    ▪ Types of Parsers - CSV, JSON, Pydantic, Structured output parser
    • Retrieval Augmented Generation (RAG)
❖ Document loaders
❖ Text Splitters
❖ Text embedding models
❖ Vector stores
❖ Retrievers
❖ Indexing
    • Agents
❖ Concepts
❖ Agent Types
❖ How to create and use Custom Agent
    • Tools
❖ Concepts
❖ Defining custom tools and using them
    • Chains
❖ Introduction to LangChain Expression Language
❖ LCEL Chains
    • Memory
❖ Chat Messages
❖ Memory types
❖ Memory in LLMChain
    • LangChain Callbacks
    • LangChain Expression Language
❖ Why use LCEL
❖ Interface
❖ Streaming
❖ Using LCEL with
    ▪ Prompt + LLM
    ▪ RAG
    ▪ Multiple chains
    ▪ Querying a SQL DB
    ▪ Agents
    ▪ Code writing
    ▪ Adding memory
    ▪ Using tools
    • LangChain Integration with
❖ Build RAG using Llama 2, Vector Store, and LangChain
❖ Local Llama 2 Q&A with LangChain
    • LangServe
❖ Features
❖ Installation
❖ Deploying an chat model example
    • LangChain Use cases implementations
❖ Summarization - Express the most important facts about a body of text
or chat interaction using RAG
❖ Question and Answering Over Documents - Use information held within
documents to answer questions or query using RAG.
❖ Extraction - Pull structured data from a body of text or an user query.
❖ Evaluation - Understand the quality of output from your application.
❖ Querying Tabular Data - Pull data from databases or other tabular
source.
❖ Code Understanding - Reason about and digest code.
❖ Interacting with APIs - Query APIs and interact with the outside world.
❖ Chatbots - A framework to have a back and forth interaction with a
user combined with memory in a chat interface.
❖ Agents - Use LLMs to make decisions about what to do next. Enable
these decisions with tools.